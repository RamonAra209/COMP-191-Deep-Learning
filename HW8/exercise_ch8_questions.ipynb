{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ee55803c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets, transforms\n",
    "import torch.optim as optim\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "03cb0579-9bcf-4f0e-b222-05c78ef37ff0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Size of cifar10 dataset 50000\n",
      "Size of cifar10 validation dataset 10000\n"
     ]
    }
   ],
   "source": [
    "# Download CIFAR 10 dataset for training and validation purposes and apply the following changes on each image:\n",
    "data_path = '../data-unversioned/p1ch7/'\n",
    "# 1) make it a tensor\n",
    "cifar10 = datasets.CIFAR10(data_path, train=True, download=True)\n",
    "cifar10_val = datasets.CIFAR10(data_path, train=False, download=True)\n",
    "\n",
    "# 2) normalize it based on the mean and standard deviation among all pixels in each channel (RGB).\n",
    "transforms.Normalize([0.4914, 0.4822, 0.4465], [0.2470, 0.2435, 0.2616])\n",
    "\n",
    "cifar10 = datasets.CIFAR10(\n",
    "    data_path, \n",
    "    train=True, \n",
    "    download=False,\n",
    "    transform=transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.4914, 0.4822, 0.4465],\n",
    "                             [0.2470, 0.2435, 0.2616])\n",
    "]))\n",
    "\n",
    "cifar10_val = datasets.CIFAR10(\n",
    "    data_path, \n",
    "    train=False, \n",
    "    download=False,\n",
    "    transform=transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.4914, 0.4822, 0.4465],\n",
    "                             [0.2470, 0.2435, 0.2616])\n",
    "]))\n",
    "\n",
    "# Print the size of training and validation datasets\n",
    "print(\"Size of cifar10 dataset\", len(cifar10))\n",
    "print(\"Size of cifar10 validation dataset\", len(cifar10_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "90374899-4072-4ee4-a3c8-a1b0ed19ce13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of cifar2 training set 15000\n",
      "Size of cifar2 validation set 3000\n"
     ]
    }
   ],
   "source": [
    "# We want to make a tertiary classifier that distinguishes between deers, dogs, and horses, labeled as 4, 5, and 7, resp.\n",
    "label_map = {4: 0, 5: 1, 7: 2}\n",
    "class_names = ['deers', 'dogs', 'horses']\n",
    "\n",
    "# Create the subset training and validation datasets for this purpose.\n",
    "ddh = [(img, label_map[label])\n",
    "          for img, label in cifar10 if label in label_map.keys()]\n",
    "\n",
    "ddh_val = [(img, label_map[label])\n",
    "             for img, label in cifar10_val if label in label_map.keys()]\n",
    "\n",
    "# Print the size of these datasets.\n",
    "print(\"Size of cifar2 training set\", len(ddh))\n",
    "print(\"Size of cifar2 validation set\", len(ddh_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5e45ff49-791b-4e63-9d35-35411a0b8abb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a parameterized CNN with the following details.\n",
    "# The parameter is the number of output channels n after the first convolution.\n",
    "\n",
    "# All kernels are of size 3 by 3.\n",
    "# Convolutions must not change the height and width.\n",
    "# Each convolution is followed by hyperbolic tangent as the activation function, and max pooling of size 2 by 2.\n",
    "# Convolution ayers:\n",
    "# 1) First convolution layer works on the input RGB input. Let's assume there are n kernels in this layer.\n",
    "# 2) Second convolution layer works on the result of the preceding max pooling layer. \n",
    "#    Let's assume there are n/2 kernels in this layer.\n",
    "# 3) Third convolution layer works on the result of the preceding max pooling layer. \n",
    "#    Let's assume there are n/2 kernels in this layer. \n",
    "\n",
    "# Fully connected layers:\n",
    "# 1) First fully connected layer works on the result of the preceding max pooling layer. \n",
    "#    This layer is followed by hyperbolic tangent as its activation function.\n",
    "# 2) Second fully connected layer works on the result of the preceding activation function, and emits numbers associated\n",
    "#    with each class.\n",
    "# We will use negative log likelihood to compute the loss. So you may add additional layer(s) to your network.\n",
    "# Note: Since the network is parameterized (n), you'd rather define the CNN as a subclass of nn.Module.\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self, n):\n",
    "        super().__init__()\n",
    "        self.n = n\n",
    "        self.conv1 = nn.Conv2d(\n",
    "                        3,     # Input Features\n",
    "                        n,     # Output Features\n",
    "                        kernel_size = 3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(n, n//2, kernel_size=3, padding=1)\n",
    "        self.conv3 = nn.Conv2d(n//2, n//2, kernel_size=3, padding=1)\n",
    "        \n",
    "        self.fc1 = nn.Linear(4 * 4 * n // 2, 32)\n",
    "        self.fc2 = nn.Linear(32, 3)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = F.max_pool2d(torch.tanh(self.conv1(x)), 2)\n",
    "        out = F.max_pool2d(torch.tanh(self.conv2(out)), 2)\n",
    "        out = F.max_pool2d(torch.tanh(self.conv3(out)), 2)\n",
    "        out = out.view(-1, 4 * 4 * (self.n // 2))\n",
    "        out = torch.tanh(self.fc1(out))\n",
    "        out = self.fc2(out)\n",
    "        out = F.log_softmax(out, dim=1)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1be13802-cee5-4150-b78c-49fae49d1c2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num parameters n=16: 6419 [432, 16, 1152, 8, 576, 8, 4096, 32, 96, 3]\n",
      "Num parameters n=32: 16163 [864, 32, 4608, 16, 2304, 16, 8192, 32, 96, 3]\n"
     ]
    }
   ],
   "source": [
    "# Create two networks as instances of the CNN you defined above, with n = 16 and n = 32 respectively.\n",
    "# Print the total number of parameters in each of these instances.\n",
    "net16 = Net(16)\n",
    "numel_list1 = [p.numel() for p in net16.parameters()]\n",
    "\n",
    "net32 = Net(32)\n",
    "numel_list2 = [p.numel() for p in net32.parameters()]\n",
    "\n",
    "print(f\"Num parameters n=16:\", sum(numel_list1), numel_list1)\n",
    "print(f\"Num parameters n=32:\", sum(numel_list2), numel_list2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b7def331-3852-4cc7-9c97-52a1d5831523",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num batches in train_loader: 469\n",
      "Num batches in val_loader: 94\n"
     ]
    }
   ],
   "source": [
    "# Our training functionality is supposed to compute gradient on batches of training data, randomly selected each time.\n",
    "# To this end, create a training data loader with batch size 32 that randomizes access to each batch.\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    ddh,\n",
    "    batch_size=32,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "# Also, create a validation data loader with the same batch size that does not randomize access to each batch (no need!)\n",
    "val_loader = torch.utils.data.DataLoader(\n",
    "    ddh_val,\n",
    "    batch_size=32,\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "# Print the number of batches in training and validation data loaders\n",
    "print(\"Num batches in train_loader:\", len(train_loader))\n",
    "print(\"Num batches in val_loader:\", len(val_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a04ef16c-813a-459a-a65c-7d710321c97b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Define your training function that receives the training loader, model, loss function, optimizer, the device (cpu/gpu), and \n",
    "# number of epochs.\n",
    "# In each epoch, you should go through each training data batch, and:\n",
    "# 1) move data to device\n",
    "# 1) compute the output batch, and accordingly the loss\n",
    "# 2) compute the gradient of loss wrt parameters, and update the parameters\n",
    "#After covering all epochs, your training function must report the training accuracy\n",
    "\n",
    "device = (torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu'))\n",
    "\n",
    "def training_loop(n_epochs, optimizer, model, loss_fn, train_loader):\n",
    "    for epoch in range(1, n_epochs + 1):\n",
    "        loss_train = 0.0\n",
    "        for imgs, labels in train_loader:\n",
    "            imgs = imgs.to(device=device)\n",
    "            labels = labels.to(device=device)\n",
    "            outputs = model(imgs)\n",
    "            loss = loss_fn(outputs, labels)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()            \n",
    "            optimizer.step()\n",
    "            \n",
    "            loss_train += loss.item()\n",
    "            \n",
    "        if epoch == 1 or epoch % 10 == 0:\n",
    "            print('{} Epoch {}, Training loss {}'.format(\n",
    "                datetime.datetime.now(), epoch,\n",
    "                loss_train / len(train_loader)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "60dfa4c0-173f-4afd-87ee-e602276f330b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define a separate function that receives the validation data loader as well as the model and computes the validation \n",
    "# accuracy of the model.\n",
    "\n",
    "def validate(model, train_loader, val_loader):\n",
    "    for name, loader in [(\"train\", train_loader), (\"val\", val_loader)]:\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        with torch.no_grad():\n",
    "            for imgs, labels in loader:\n",
    "                outputs = model(imgs)\n",
    "                _, predicted = torch.max(outputs, dim=1)\n",
    "                total += labels.shape[0]\n",
    "                correct += int((predicted == labels).sum())\n",
    "        print(\"Accuracy {}: {:.6f}\".format(name, correct / total))                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "033e6166-15b7-4a07-aab5-eebbb2acc386",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-11-01 11:41:41.845144 Epoch 1, Training loss 0.654270358939669\n",
      "2022-11-01 11:42:33.092243 Epoch 10, Training loss 0.5569176901060381\n",
      "2022-11-01 11:43:30.546001 Epoch 20, Training loss 0.49230227748086963\n",
      "2022-11-01 11:44:27.927335 Epoch 30, Training loss 0.44867011641007243\n",
      "2022-11-01 11:45:25.950282 Epoch 40, Training loss 0.41881244697931735\n",
      "2022-11-01 11:46:23.704218 Epoch 50, Training loss 0.3925727288415437\n",
      "2022-11-01 11:47:21.887784 Epoch 60, Training loss 0.37409245538940306\n",
      "2022-11-01 11:48:19.446432 Epoch 70, Training loss 0.3541500512629684\n",
      "2022-11-01 11:49:17.856360 Epoch 80, Training loss 0.3369169139595174\n",
      "2022-11-01 11:50:15.528003 Epoch 90, Training loss 0.3231539800445408\n",
      "2022-11-01 11:51:13.214216 Epoch 100, Training loss 0.30514395502266856\n",
      "Accuracy train: 0.88\n",
      "Accuracy val: 0.79\n"
     ]
    }
   ],
   "source": [
    "#Define device dynamically based on whether CUDA is available or not.\n",
    "#Call the training function on the created training data loader, the created CNN  with n = 16, \n",
    "# negative log likelihood loss function, stochastic gradient descent optimizer,\n",
    "training_loop(\n",
    "    n_epochs=100,\n",
    "    optimizer=optim.SGD(net16.parameters(), lr=1e-2),\n",
    "    model=net16.to(device),\n",
    "    loss_fn=nn.NLLLoss(),\n",
    "    train_loader=train_loader\n",
    ")\n",
    "\n",
    "# the device you defined, and 100 epochs. Next, call validation accuracy function.\n",
    "validate(net16, train_loader, val_loader)\n",
    "\n",
    "# Is the model overfit? (Yes/No) Why?\n",
    "\"\"\" \n",
    "Yes the model is overfitting. This is because the training accuracy is higher than\n",
    "the validation accuracy. This is the case as overfitting occurs when the model 'memorizes'\n",
    "the training data, so it can't account for new data as well as it should.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5d2f930c-039d-4123-b90d-60fac6d68afa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-11-02 21:56:52.520799 Epoch 1, Training loss 0.9502991778509957\n",
      "2022-11-02 21:58:14.746871 Epoch 10, Training loss 0.5868856079542815\n",
      "2022-11-02 21:59:47.706872 Epoch 20, Training loss 0.43791962750176633\n",
      "2022-11-02 22:01:20.563949 Epoch 30, Training loss 0.35799328086854043\n",
      "2022-11-02 22:02:51.652702 Epoch 40, Training loss 0.29481443406136304\n",
      "2022-11-02 22:04:22.759750 Epoch 50, Training loss 0.24518273811318728\n",
      "2022-11-02 22:05:54.407728 Epoch 60, Training loss 0.20082846441979346\n",
      "2022-11-02 22:07:25.540392 Epoch 70, Training loss 0.1589053879255679\n",
      "2022-11-02 22:08:49.253886 Epoch 80, Training loss 0.12469892978850904\n",
      "2022-11-02 22:10:12.940467 Epoch 90, Training loss 0.09698326696655643\n",
      "2022-11-02 22:11:36.563118 Epoch 100, Training loss 0.06857202563887593\n",
      "Accuracy train: 0.979067\n",
      "Accuracy val: 0.791333\n"
     ]
    }
   ],
   "source": [
    "#Call the training function on the created training data loader, the created CNN  with n = 32, \n",
    "# negative log likelihood loss function, stochastic gradient descent optimizer,\n",
    "# the device you defined, and 100 epochs. Next, call validation accuracy function.\n",
    "training_loop(\n",
    "    n_epochs=100,\n",
    "    optimizer=optim.SGD(net32.parameters(), lr=1e-2),\n",
    "    model=net32.to(device=device),\n",
    "    loss_fn=nn.NLLLoss(),\n",
    "    train_loader=train_loader\n",
    ")\n",
    "validate(net32, train_loader, val_loader)\n",
    "#Is the model overfit? (Yes/No) Why? \n",
    "# (This can be compared to the fully connected network we created in the last set of exercises.)\n",
    "\"\"\" Yes the model is overfitting since training accuracy > validation accuracy \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1dde7111-bf9d-4a9b-b5df-f782586e60b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-11-02 22:11:48.869234 Epoch 1, Training loss 1.0569783700808788\n",
      "2022-11-02 22:13:04.833227 Epoch 10, Training loss 0.6066836116791788\n",
      "2022-11-02 22:14:28.948842 Epoch 20, Training loss 0.45806187238774576\n",
      "2022-11-02 22:15:55.198303 Epoch 30, Training loss 0.381322596341308\n",
      "2022-11-02 22:17:21.793784 Epoch 40, Training loss 0.3320629875034666\n",
      "2022-11-02 22:18:48.430035 Epoch 50, Training loss 0.2860628360115897\n",
      "2022-11-02 22:20:15.688400 Epoch 60, Training loss 0.24858584910281686\n",
      "2022-11-02 22:21:42.692607 Epoch 70, Training loss 0.21554245650450557\n",
      "2022-11-02 22:23:10.367880 Epoch 80, Training loss 0.18598151354313786\n",
      "2022-11-02 22:24:38.396354 Epoch 90, Training loss 0.1636426716105643\n",
      "2022-11-02 22:26:06.282527 Epoch 100, Training loss 0.14222606266739526\n",
      "Accuracy train: 0.951467\n",
      "Accuracy val: 0.797000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "' Yes the model is overfitting since training accuracy > validation accuracy '"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Next, let's consider L2 regularization with weight decay 0.002 for CNN with n = 32. \n",
    "net32_2 = Net(32)\n",
    "training_loop(\n",
    "    n_epochs=100,\n",
    "    optimizer=optim.SGD(net32_2.parameters(), lr=1e-2, weight_decay=0.002),\n",
    "    model=net32_2.to(device),\n",
    "    loss_fn=nn.NLLLoss(),\n",
    "    train_loader=train_loader\n",
    ")\n",
    "validate(net32_2, train_loader, val_loader)\n",
    "# Is the model overfit? (Yes/No) Why?\n",
    "\"\"\" Yes the model is overfitting since training accuracy > validation accuracy \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6b8e315a-0f42-4dbf-b641-6c11fbe206e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-11-02 22:27:19.979009 Epoch 1, Training loss 1.0131968244560745\n",
      "2022-11-02 22:28:38.544993 Epoch 10, Training loss 0.5390585403579639\n",
      "2022-11-02 22:30:07.462849 Epoch 20, Training loss 0.41773005338238756\n",
      "2022-11-02 22:31:36.063490 Epoch 30, Training loss 0.34915744592703735\n",
      "2022-11-02 22:33:04.987188 Epoch 40, Training loss 0.29912021371728575\n",
      "2022-11-02 22:34:33.860877 Epoch 50, Training loss 0.2578638298615718\n",
      "2022-11-02 22:36:03.176691 Epoch 60, Training loss 0.22210906704923492\n",
      "2022-11-02 22:37:32.796424 Epoch 70, Training loss 0.19374022058554805\n",
      "2022-11-02 22:39:02.834254 Epoch 80, Training loss 0.16686274939730986\n",
      "2022-11-02 22:40:32.633224 Epoch 90, Training loss 0.14496466477336026\n",
      "2022-11-02 22:42:02.775554 Epoch 100, Training loss 0.12289860671453638\n",
      "Accuracy train: 0.970533\n",
      "Accuracy val: 0.827333\n"
     ]
    }
   ],
   "source": [
    "#Add a skip connection in your CNN from the output of second max pooling to the input of 3rd max pooling.\n",
    "\n",
    "class ResNet(nn.Module): # Book did resnet\n",
    "    def __init__(self, n):\n",
    "        super().__init__()\n",
    "        self.n = n\n",
    "        self.conv1 = nn.Conv2d(\n",
    "                        3,     # Input Features\n",
    "                        n,     # Output Features\n",
    "                        kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(n, n//2, kernel_size=3, padding=1)\n",
    "        self.conv3 = nn.Conv2d(n//2, n//2, kernel_size=3, padding=1)\n",
    "        \n",
    "        self.fc1 = nn.Linear(4 * 4 * n // 2, 32)\n",
    "        self.fc2 = nn.Linear(32, 3)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = F.max_pool2d(torch.tanh(self.conv1(x)), 2)\n",
    "        out = F.max_pool2d(torch.tanh(self.conv2(out)), 2)\n",
    "        skip_connection = out\n",
    "        out = F.max_pool2d(torch.tanh(self.conv3(out)) + skip_connection, 2)\n",
    "        out = out.view(-1, 4 * 4 * (self.n // 2))\n",
    "        out = torch.tanh(self.fc1(out))\n",
    "        out = self.fc2(out)\n",
    "        out = F.log_softmax(out, dim=1)\n",
    "        return out\n",
    "    \n",
    "#Train the updated CNN with the same parameters including (n = 32).\n",
    "net32_skip_connection = ResNet(32)\n",
    "training_loop(\n",
    "    n_epochs=100,\n",
    "    optimizer=optim.SGD(net32_skip_connection.parameters(), lr=1e-2, weight_decay=0.002),\n",
    "    model=net32_skip_connection.to(device),\n",
    "    loss_fn=nn.NLLLoss(),\n",
    "    train_loader=train_loader\n",
    ")\n",
    "validate(net32_skip_connection, train_loader, val_loader)\n",
    "\n",
    "#Is the model overfit? (Yes/No) Why?\n",
    "\"\"\" Yes the model is overfitting since training accuracy > validation accuracy \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a4ebfaac-1a04-4695-aa15-c83f86290c36",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "nll_loss_nd(): argument 'input' (position 1) must be Tensor, not NoneType",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [22]\u001b[0m, in \u001b[0;36m<cell line: 36>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[38;5;66;03m#Train the updated CNN with the same parameters including (n = 32).\u001b[39;00m\n\u001b[1;32m     35\u001b[0m net32_drop_out \u001b[38;5;241m=\u001b[39m NetDropout(\u001b[38;5;241m32\u001b[39m)\n\u001b[0;32m---> 36\u001b[0m \u001b[43mtraining_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     37\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     38\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptim\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mSGD\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnet32_drop_out\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparameters\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1e-2\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     39\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnet32_drop_out\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     40\u001b[0m \u001b[43m    \u001b[49m\u001b[43mloss_fn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mNLLLoss\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     41\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_loader\u001b[49m\n\u001b[1;32m     42\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m     43\u001b[0m validate(net32_drop_out, train_loader, val_loader)\n",
      "Input \u001b[0;32mIn [17]\u001b[0m, in \u001b[0;36mtraining_loop\u001b[0;34m(n_epochs, optimizer, model, loss_fn, train_loader)\u001b[0m\n\u001b[1;32m     16\u001b[0m labels \u001b[38;5;241m=\u001b[39m labels\u001b[38;5;241m.\u001b[39mto(device\u001b[38;5;241m=\u001b[39mdevice)\n\u001b[1;32m     17\u001b[0m outputs \u001b[38;5;241m=\u001b[39m model(imgs)\n\u001b[0;32m---> 18\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[43mloss_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     20\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m     21\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()            \n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.10/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1131\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.10/site-packages/torch/nn/modules/loss.py:211\u001b[0m, in \u001b[0;36mNLLLoss.forward\u001b[0;34m(self, input, target)\u001b[0m\n\u001b[1;32m    210\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor, target: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 211\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnll_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mignore_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mignore_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreduction\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreduction\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.10/site-packages/torch/nn/functional.py:2689\u001b[0m, in \u001b[0;36mnll_loss\u001b[0;34m(input, target, weight, size_average, ignore_index, reduce, reduction)\u001b[0m\n\u001b[1;32m   2687\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m size_average \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m reduce \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   2688\u001b[0m     reduction \u001b[38;5;241m=\u001b[39m _Reduction\u001b[38;5;241m.\u001b[39mlegacy_get_string(size_average, reduce)\n\u001b[0;32m-> 2689\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_C\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_nn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnll_loss_nd\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_Reduction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_enum\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreduction\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mignore_index\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mTypeError\u001b[0m: nll_loss_nd(): argument 'input' (position 1) must be Tensor, not NoneType"
     ]
    }
   ],
   "source": [
    "#Consider dropout layers after each max pooling in the original CNN, where the probability of zeroing output features is 30%.\n",
    "class NetDropout(nn.Module): # Book did NetDropout\n",
    "    def __init__(self, n):\n",
    "        super().__init__()\n",
    "        self.n = n\n",
    "        self.conv1 = nn.Conv2d(\n",
    "                        3,     # Input Features\n",
    "                        n,     # Output Features\n",
    "                        kernel_size=3, padding=1)\n",
    "        self.conv1_dropout = nn.Dropout2d(p=0.3)\n",
    "        self.conv2 = nn.Conv2d(n, n//2, kernel_size=3, padding=1)\n",
    "        self.conv2_dropout = nn.Dropout2d(p=0.3)\n",
    "        self.conv3 = nn.Conv2d(n//2, n//2, kernel_size=3, padding=1)\n",
    "        self.conv3_dropout = nn.Dropout2d(p=0.3)\n",
    "        \n",
    "        self.fc1 = nn.Linear(4 * 4 * n // 2, 32)\n",
    "        self.fc2 = nn.Linear(32, 3)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = F.max_pool2d(torch.tanh(self.conv1(x)), 2)\n",
    "        out = self.conv1_dropout(out)\n",
    "        \n",
    "        out = F.max_pool2d(torch.tanh(self.conv2(out)), 2)\n",
    "        out = self.conv2_dropout(out)\n",
    "        \n",
    "        out = F.max_pool2d(torch.tanh(self.conv3(out)), 2)\n",
    "        out = self.conv3_dropout(out)\n",
    "        \n",
    "        out = out.view(-1, 4 * 4 * (self.n // 2))\n",
    "        out = torch.tanh(self.fc1(out))\n",
    "        out = self.fc2(out)\n",
    "        out = F.log_softmax(out, dim=1)\n",
    "        \n",
    "#Train the updated CNN with the same parameters including (n = 32).\n",
    "net32_drop_out = NetDropout(32)\n",
    "training_loop(\n",
    "    n_epochs=100,\n",
    "    optimizer=optim.SGD(net32_drop_out.parameters(), lr=1e-2),\n",
    "    model=net32_drop_out.to(device),\n",
    "    loss_fn=nn.NLLLoss(),\n",
    "    train_loader=train_loader\n",
    ")\n",
    "validate(net32_drop_out, train_loader, val_loader)\n",
    "#Is the model overfit? (Yes/No) Why?\n",
    "\"\"\" I literally don't know how to fix the error this function is throwing, its an internal error \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "33917fa1-51d7-42cb-808d-7caa06ef8908",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Considering all the modifications which one works better? Plain CNN, CNN+L2, CNN+Skip, CNN+Dropout?\n",
    "\"\"\" \n",
    "Since I can only compare the first three, because theres an internal error happening in DropOut..\n",
    "I'm going to guess that a CNN with Skip Layer is the best amongst the three tested\n",
    "This is because it has the highest trianing & validation accuracies, with relatively lower\n",
    "overfitting.\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
